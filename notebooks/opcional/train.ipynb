{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f801388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from ultralytics import YOLO, RTDETR\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "# Agregar el root del proyecto al path\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "from src.main import load_config\n",
    "from scripts.get_stats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf39e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GET STATS: Analizando Dataset Global (data\\processed\\all_labels) ---\n",
      " No existe data\\processed\\all_labels. Ejecuta data_processing primero.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\src\\main.py:237\u001b[39m, in \u001b[36mget_stats\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[33;03mGenera un reporte técnico del dataset:\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m- Descripción de inputs/outputs (Features).\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m- Conteo de instancias por clase y split.\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[33;03mGuarda resultados en models/metrics/\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    236\u001b[39m config = load_config()\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[43mgenerate_stats_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\src\\get_stats\\analysis.py:116\u001b[39m, in \u001b[36mgenerate_stats_report\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    113\u001b[39m df_feat.to_csv(metrics_dir / \u001b[33m\"\u001b[39m\u001b[33mdataset_features.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# 2. Global Stats (Processed)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m df_global, n_imgs, n_anns = analyze_global_stats(config)\n\u001b[32m    117\u001b[39m global_path = metrics_dir / \u001b[33m\"\u001b[39m\u001b[33mglobal_stats.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_global.empty:\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1113e358",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad09caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LÓGICA PRINCIPAL DE ENTRENAMIENTO =====\n",
    "def train():\n",
    "    config = load_config()\n",
    "    root_path = config['root_path']\n",
    "    # -- Rutas --\n",
    "    # splits_path = Path(config['paths']['splits_path'])\n",
    "    # dataset_yaml = splits_path / \"dataset.yaml\"\n",
    "    dataset_yaml = \"dataset.yaml\"\n",
    "    #Output\n",
    "    # output_dir = root_path / \"models\" / \"artifacts\"\n",
    "    output_dir = \"data/models/artifacts/yolo_v8\"  # Concatenación simple para evitar problemas de Path en Windows\n",
    "    #Crear output_dir si no existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"root_path: {root_path}\")\n",
    "    print(f\"dataset_yaml: {dataset_yaml}\")\n",
    "    print(f\"output_dir: {output_dir}\")\n",
    "\n",
    "    # Inicializar modelo YOLOv8s preentrenado\n",
    "    model = YOLO('yolov8s.pt')\n",
    "\n",
    "    # Configurar PARAMETROS DE ENTRENAMIENTO\n",
    "    epochs = config['training']['epochs']\n",
    "    batch_size = config['training']['batch_size']\n",
    "    device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "    # Iniciar entrenamiento\n",
    "    \n",
    "    results = model.train(\n",
    "        data=dataset_yaml,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,\n",
    "        imgsz=640,\n",
    "        project=str(output_dir),\n",
    "        name=\"yolo_run\",\n",
    "        exist_ok=True,\n",
    "        pretrained=True,\n",
    "        plots=True,\n",
    "        device=device,\n",
    "        workers=4\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4c16027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_path: C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\n",
      "dataset_yaml: dataset.yaml\n",
      "output_dir: data/models/artifacts/\n",
      "New https://pypi.org/project/ultralytics/8.4.14 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.11  Python-3.12.3 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24564MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=yolo_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=data/models/artifacts/, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\data\\models\\artifacts\\yolo_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.head.Detect           [5, 16, None, [128, 256, 512]]\n",
      "Model summary: 130 layers, 11,137,535 parameters, 11,137,519 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ━━━━━━━━━━━━ 5.3MB 59.7MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 411.785.0 MB/s, size: 621.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\splits\\train\\labels.cache... 2339 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2339/2339  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 457.644.9 MB/s, size: 668.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\splits\\val\\labels.cache... 438 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 438/438  0.0s\n",
      "Plotting labels to C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\data\\models\\artifacts\\yolo_run\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\data\\models\\artifacts\\yolo_run\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      7.23G      1.915      1.707      1.504         72        640: 100% ━━━━━━━━━━━━ 74/74 5.5it/s 13.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s0.3s\n",
      "                   all        438       5399      0.516       0.66      0.592      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      7.88G      1.611      1.079      1.287         98        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399      0.656      0.585      0.651      0.325\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      8.22G      1.577      1.007      1.272         63        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        438       5399      0.647      0.626      0.655      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      8.22G      1.556     0.9783      1.268         55        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399       0.62      0.657      0.649      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      8.22G      1.521     0.9387       1.26         58        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        438       5399      0.653      0.676      0.671      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      8.22G       1.47     0.8959      1.234         15        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.6it/s 1.5s0.2s\n",
      "                   all        438       5399      0.685      0.715      0.735       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      8.22G      1.431      0.851      1.217         37        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.4it/s 1.6s0.3s\n",
      "                   all        438       5399      0.722        0.7       0.72      0.383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      8.22G      1.412     0.8208      1.204         72        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        438       5399      0.684      0.722      0.758      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      8.96G      1.391      0.806      1.191         50        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.5s0.3s\n",
      "                   all        438       5399      0.698      0.759      0.765      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      8.96G       1.36     0.7784      1.181         31        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.4it/s 1.6s0.3s\n",
      "                   all        438       5399      0.687      0.751      0.739      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      8.96G      1.354     0.7629      1.176         74        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        438       5399      0.738      0.769      0.798      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      8.96G      1.327     0.7434      1.165         62        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.5s0.3s\n",
      "                   all        438       5399      0.766      0.747      0.784      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      8.96G      1.308     0.7284      1.164         34        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399      0.724      0.759       0.76      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      8.96G      1.294     0.7178      1.155         78        640: 100% ━━━━━━━━━━━━ 74/74 6.9it/s 10.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.6it/s 1.5s0.3s\n",
      "                   all        438       5399      0.719      0.721       0.74      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      8.96G      1.277     0.6962      1.148        113        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        438       5399      0.755      0.746      0.776      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      8.96G       1.27     0.6925      1.146         39        640: 100% ━━━━━━━━━━━━ 74/74 7.2it/s 10.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399        0.7      0.753      0.738      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      8.96G       1.23     0.6718      1.127         55        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.7it/s 1.5s0.3s\n",
      "                   all        438       5399      0.708      0.792      0.755      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      8.96G      1.235     0.6738      1.131         80        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        438       5399      0.739      0.733      0.755      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      8.96G      1.224     0.6533      1.122         95        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.4it/s 1.6s0.3s\n",
      "                   all        438       5399      0.767      0.745      0.791      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      8.96G      1.206     0.6435      1.114         60        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s0.3s\n",
      "                   all        438       5399      0.764       0.75       0.79      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      8.96G      1.206     0.6374      1.117         53        640: 100% ━━━━━━━━━━━━ 74/74 6.9it/s 10.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        438       5399      0.737      0.785       0.79      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      8.96G      1.176     0.6227      1.102        147        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        438       5399      0.764      0.785      0.797      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      8.96G       1.17     0.6197      1.103         56        640: 100% ━━━━━━━━━━━━ 74/74 6.9it/s 10.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399      0.749      0.762       0.78      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      8.96G      1.178     0.6155      1.102         68        640: 100% ━━━━━━━━━━━━ 74/74 6.9it/s 10.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s0.3s\n",
      "                   all        438       5399      0.785      0.707      0.775      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      8.96G      1.146     0.6006       1.09         50        640: 100% ━━━━━━━━━━━━ 74/74 6.8it/s 10.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s0.3s\n",
      "                   all        438       5399      0.773      0.769      0.778      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      8.96G      1.134     0.5934      1.086         56        640: 100% ━━━━━━━━━━━━ 74/74 6.6it/s 11.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s0.3s\n",
      "                   all        438       5399      0.731      0.773      0.764      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      8.96G       1.12     0.5818      1.077         57        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399      0.744       0.78      0.767       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      8.96G      1.116     0.5809      1.082         83        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        438       5399       0.77       0.76      0.781      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      8.96G      1.106     0.5728      1.072         71        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399       0.77      0.747      0.784      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      8.96G      1.093     0.5671      1.069         44        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s0.3s\n",
      "                   all        438       5399       0.76      0.775      0.799       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      8.96G      1.083     0.5614      1.064         42        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        438       5399      0.767      0.758      0.789      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      8.96G      1.085     0.5581      1.066         47        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        438       5399      0.767      0.775      0.787      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      8.96G      1.074     0.5521      1.059         75        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        438       5399      0.765      0.767       0.78       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      8.96G      1.078     0.5506      1.064         27        640: 100% ━━━━━━━━━━━━ 74/74 6.9it/s 10.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.4it/s 1.6s0.3s\n",
      "                   all        438       5399       0.75      0.776      0.773      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      8.96G      1.041     0.5375      1.049         31        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        438       5399      0.767      0.745      0.781      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      8.96G      1.058     0.5377      1.056         31        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        438       5399      0.764      0.761      0.779      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      8.96G      1.044     0.5309      1.048         75        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        438       5399      0.776      0.752      0.782      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      8.96G      1.043     0.5248       1.05         46        640: 100% ━━━━━━━━━━━━ 74/74 7.0it/s 10.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        438       5399      0.766      0.746      0.779      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      8.96G      1.028     0.5201      1.049         85        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        438       5399      0.774       0.77      0.789      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      8.96G       1.02     0.5157      1.039         35        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399      0.786      0.753      0.782      0.446\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      8.96G      1.015     0.4957      1.048         41        640: 100% ━━━━━━━━━━━━ 74/74 6.3it/s 11.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        438       5399      0.747      0.773      0.775       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      8.96G     0.9775     0.4696      1.033         60        640: 100% ━━━━━━━━━━━━ 74/74 7.2it/s 10.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.6it/s 1.5s0.2s\n",
      "                   all        438       5399      0.748      0.773      0.786      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      8.96G     0.9717      0.469      1.027         43        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.9it/s 1.4s0.2s\n",
      "                   all        438       5399      0.751      0.771      0.779      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      8.96G     0.9619     0.4604      1.025         49        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.3s0.2s\n",
      "                   all        438       5399      0.774      0.765      0.779      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      8.96G     0.9592     0.4557      1.024         38        640: 100% ━━━━━━━━━━━━ 74/74 7.2it/s 10.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.5s0.3s\n",
      "                   all        438       5399      0.773       0.76      0.783      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      8.96G     0.9398     0.4478      1.018         41        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.0it/s 1.4s0.2s\n",
      "                   all        438       5399      0.772      0.763      0.783      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      8.96G     0.9378     0.4464      1.014          8        640: 100% ━━━━━━━━━━━━ 74/74 7.3it/s 10.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.4s0.2s\n",
      "                   all        438       5399      0.771      0.749      0.774      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      8.96G     0.9316     0.4413      1.017         20        640: 100% ━━━━━━━━━━━━ 74/74 7.2it/s 10.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.3it/s 1.3s0.2s\n",
      "                   all        438       5399       0.78      0.749      0.783      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      8.96G     0.9229     0.4424      1.011         21        640: 100% ━━━━━━━━━━━━ 74/74 7.3it/s 10.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.7it/s 1.5s0.2s\n",
      "                   all        438       5399      0.771      0.763      0.787      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      8.96G     0.9053     0.4331      1.005         25        640: 100% ━━━━━━━━━━━━ 74/74 7.1it/s 10.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.3it/s 1.3s0.2s\n",
      "                   all        438       5399      0.753      0.781      0.783      0.451\n",
      "\n",
      "50 epochs completed in 0.178 hours.\n",
      "Optimizer stripped from C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\data\\models\\artifacts\\yolo_run\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\data\\models\\artifacts\\yolo_run\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\data\\models\\artifacts\\yolo_run\\weights\\best.pt...\n",
      "Ultralytics 8.4.11  Python-3.12.3 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24564MiB)\n",
      "Model summary (fused): 73 layers, 11,127,519 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.5it/s 2.0s0.3s\n",
      "                   all        438       5399      0.761      0.776      0.798       0.46\n",
      "                 stand        410       2379      0.845      0.863      0.904      0.518\n",
      "            lying_down        365       1229      0.873      0.852      0.888      0.453\n",
      "              foraging        223        825      0.762      0.833      0.848      0.542\n",
      "        drinking_water         89        105      0.586      0.648      0.623      0.374\n",
      "            rumination        289        861       0.74      0.683       0.73      0.412\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\data\\models\\artifacts\\yolo_run\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08288e",
   "metadata": {},
   "source": [
    "# RTDETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ef81940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_cnn(num_classes=3):\n",
    "    # Usamos ResNet18 como backbone de una CNN simple para clasificación\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    # Ajustamos la última capa para nuestras clases (Standing, Eating, Lying) [cite: 100, 105]\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99ec5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rtdetr():\n",
    "    config = load_config()\n",
    "    dataset_yaml = \"dataset.yaml\"\n",
    "    output_dir = \"models/artifacts/rtdetr\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Cargamos la variante preentrenada de RT-DETR-L\n",
    "    model = RTDETR('rtdetr-l.pt')\n",
    "\n",
    "    results = model.train(\n",
    "        data=dataset_yaml,\n",
    "        epochs=config['training']['epochs'],\n",
    "        batch=config['training']['batch_size'],\n",
    "        imgsz=640,\n",
    "        project=output_dir,\n",
    "        name=\"experiment\",\n",
    "        device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "        pretrained=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ed00882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/rtdetr-l.pt to 'rtdetr-l.pt': 100% ━━━━━━━━━━━━ 63.4MB 32.3MB/s 2.0s1.9s<0.2s\n",
      "New https://pypi.org/project/ultralytics/8.4.14 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.11  Python-3.12.3 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24564MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=experiment, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=models/artifacts/rtdetr, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "WARNING no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7312127  ultralytics.nn.modules.head.RTDETRDecoder    [5, [256, 256, 256]]          \n",
      "rt-detr-l summary: 465 layers, 32,816,351 parameters, 32,816,351 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 3623.5376.0 MB/s, size: 621.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\splits\\train\\labels.cache... 2339 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2339/2339  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1240.7358.1 MB/s, size: 668.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\splits\\val\\labels.cache... 438 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 438/438  0.0s\n",
      "Plotting labels to C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/50      24.2G      1.053      1.215     0.6102         56        640: 100% ━━━━━━━━━━━━ 74/74 7.1s/it 8:447.5s5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.0s/it 7.3s0.5ss\n",
      "                   all        438       5399      0.658      0.497      0.467      0.221\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/50      23.6G     0.5899     0.5535     0.2094         36        640: 100% ━━━━━━━━━━━━ 74/74 3.6s/it 4:290.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.5it/s 2.9s0.5s\n",
      "                   all        438       5399      0.772      0.604      0.611      0.304\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/50      24.3G     0.5368     0.5391     0.1851         93        640: 100% ━━━━━━━━━━━━ 74/74 4.7s/it 5:503.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.1s/it 8.0s0.6ss\n",
      "                   all        438       5399       0.55      0.679      0.622      0.328\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/50      22.7G     0.5266     0.5234     0.1785         48        640: 100% ━━━━━━━━━━━━ 74/74 1.9s/it 2:210.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.1it/s 3.3s0.6ss\n",
      "                   all        438       5399      0.654      0.754      0.694      0.381\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/50      22.8G     0.5104     0.5074     0.1726         80        640: 100% ━━━━━━━━━━━━ 74/74 7.9s/it 9:461.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.4s0.7ss\n",
      "                   all        438       5399      0.679      0.751      0.738      0.411\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/50      22.6G     0.4975     0.4995     0.1665         51        640: 100% ━━━━━━━━━━━━ 74/74 2.0s/it 2:241.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.7s0.8ss\n",
      "                   all        438       5399      0.723      0.806      0.786      0.445\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/50        24G     0.4802     0.4871       0.16         42        640: 100% ━━━━━━━━━━━━ 74/74 13.7s/it 16:52.8s7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.2s/it 8.1s0.6ss\n",
      "                   all        438       5399      0.732      0.759       0.78      0.445\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/50      24.1G     0.4722     0.4827     0.1554         61        640: 100% ━━━━━━━━━━━━ 74/74 4.9s/it 6:021.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.9it/s 3.7s0.6ss\n",
      "                   all        438       5399      0.712      0.771      0.756      0.428\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/50      23.8G     0.4863     0.4766     0.1657        558        640: 0% ──────────── 0/74  3.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/50      23.8G     0.4619     0.4755     0.1546         55        640: 100% ━━━━━━━━━━━━ 74/74 5.5s/it 6:467.0s3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.2s/it 8.5s0.6ss\n",
      "                   all        438       5399      0.734      0.727      0.748      0.402\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/50      23.6G      0.458     0.4737      0.153         41        640: 100% ━━━━━━━━━━━━ 74/74 3.1s/it 3:461.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.9it/s 3.7s0.6ss\n",
      "                   all        438       5399      0.755      0.768      0.785       0.43\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/50      23.9G     0.4632     0.4487     0.1597        500        640: 0% ──────────── 0/74  7.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/50      23.9G     0.4485     0.4695     0.1487         53        640: 100% ━━━━━━━━━━━━ 74/74 16.7s/it 20:39.6s9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.1it/s 6.1s0.8ss\n",
      "                   all        438       5399      0.742       0.77      0.777      0.444\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/50      24.1G     0.4436     0.4636     0.1497         38        640: 100% ━━━━━━━━━━━━ 74/74 3.6s/it 4:290.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.7it/s 2.6s0.4s\n",
      "                   all        438       5399      0.742      0.793       0.78      0.438\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/50      24.3G     0.4338     0.4553     0.1417         43        640: 100% ━━━━━━━━━━━━ 74/74 2.2s/it 2:411.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.4it/s 3.0s0.5s\n",
      "                   all        438       5399       0.77      0.765      0.799       0.46\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/50      23.2G      0.429     0.4522     0.1414         36        640: 100% ━━━━━━━━━━━━ 74/74 1.3s/it 1:360.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.7it/s 2.6s0.4s\n",
      "                   all        438       5399      0.745      0.744      0.777      0.444\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/50      24.2G     0.4242     0.4503     0.1389         52        640: 100% ━━━━━━━━━━━━ 74/74 2.7s/it 3:210.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        438       5399      0.755       0.76      0.781       0.45\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/50      22.3G     0.4261     0.4375     0.1446        569        640: 0% ──────────── 0/74  0.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/50      22.7G      0.418     0.4412     0.1357         19        640: 100% ━━━━━━━━━━━━ 74/74 1.2s/it 1:290.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.4s0.7ss\n",
      "                   all        438       5399      0.709      0.782      0.741      0.425\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/50      22.7G     0.4149       0.44     0.1365         36        640: 100% ━━━━━━━━━━━━ 74/74 1.1it/s 1:090.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.7it/s 2.6s0.4s\n",
      "                   all        438       5399      0.768      0.746      0.784      0.456\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/50      24.3G     0.4054     0.4348     0.1304         63        640: 100% ━━━━━━━━━━━━ 74/74 4.6s/it 5:392.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.4it/s 2.9s0.5s\n",
      "                   all        438       5399      0.746      0.753      0.762      0.435\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/50      22.6G        0.4     0.4321       0.13         71        640: 100% ━━━━━━━━━━━━ 74/74 1.2it/s 1:010.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        438       5399      0.768       0.77      0.774      0.445\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/50      23.7G     0.4014     0.4299     0.1321         23        640: 100% ━━━━━━━━━━━━ 74/74 2.2s/it 2:440.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.9it/s 2.4s0.4s\n",
      "                   all        438       5399      0.769      0.758      0.761      0.444\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      21/50      23.9G     0.3956     0.4295     0.1296         38        640: 100% ━━━━━━━━━━━━ 74/74 2.8s/it 3:311.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.0s0.7ss\n",
      "                   all        438       5399       0.73      0.768       0.77      0.438\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      22/50        24G     0.3933     0.4174      0.129         35        640: 100% ━━━━━━━━━━━━ 74/74 2.1s/it 2:320.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.6it/s 2.7s0.4ss\n",
      "                   all        438       5399      0.772      0.747      0.773      0.439\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      23/50      23.1G     0.3918     0.4092     0.1213        644        640: 0% ──────────── 0/74  1.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      23/50      23.1G     0.3905     0.4171     0.1283         86        640: 100% ━━━━━━━━━━━━ 74/74 2.5s/it 3:081.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.4it/s 3.0s0.5s\n",
      "                   all        438       5399      0.772      0.743      0.765      0.447\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      24/50      22.9G     0.3794     0.4126     0.1238         39        640: 100% ━━━━━━━━━━━━ 74/74 1.1s/it 1:240.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        438       5399       0.78      0.778      0.789      0.453\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      25/50        24G     0.3758     0.4125      0.122         18        640: 100% ━━━━━━━━━━━━ 74/74 3.9s/it 4:510.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        438       5399      0.766      0.769      0.785      0.455\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      26/50      24.2G     0.3781     0.4133     0.1219         54        640: 100% ━━━━━━━━━━━━ 74/74 15.4s/it 19:02.1s3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.0s/it 7.1s0.5ss\n",
      "                   all        438       5399       0.77      0.753      0.783      0.449\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      27/50      22.7G     0.3716     0.4108     0.1188         36        640: 100% ━━━━━━━━━━━━ 74/74 1.9s/it 2:200.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.6it/s 2.7s0.4s\n",
      "                   all        438       5399      0.762      0.764      0.769      0.443\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      28/50      22.9G     0.3492     0.4054     0.1113        600        640: 0% ──────────── 0/74  2.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      28/50      22.9G     0.3685     0.4042     0.1191         41        640: 100% ━━━━━━━━━━━━ 74/74 1.8s/it 2:150.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.8it/s 3.8s0.6ss\n",
      "                   all        438       5399      0.772      0.789      0.806      0.461\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      29/50      22.6G     0.3684     0.4057     0.1182         29        640: 100% ━━━━━━━━━━━━ 74/74 1.7s/it 2:050.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.3it/s 5.2s0.8ss\n",
      "                   all        438       5399      0.746      0.766      0.759      0.436\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      30/50      22.6G     0.3806     0.4187     0.1086        624        640: 0% ──────────── 0/74  1.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      30/50      22.8G     0.3643     0.4016     0.1181         79        640: 100% ━━━━━━━━━━━━ 74/74 1.7s/it 2:020.9sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.5it/s 2.8s0.5s\n",
      "                   all        438       5399      0.763      0.768      0.776      0.453\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      31/50      23.2G      0.362     0.3997     0.1158         72        640: 100% ━━━━━━━━━━━━ 74/74 2.0s/it 2:260.7ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.2it/s 3.2s0.5s\n",
      "                   all        438       5399      0.733      0.793      0.776      0.453\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      32/50      22.8G     0.3762      0.399     0.1306        533        640: 0% ──────────── 0/74  2.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      32/50      22.8G     0.3628     0.3969      0.117         16        640: 100% ━━━━━━━━━━━━ 74/74 5.5s/it 6:442.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.1it/s 6.5s0.6ss\n",
      "                   all        438       5399      0.781      0.786      0.788      0.464\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      33/50      22.8G     0.3545     0.3976     0.1148         31        640: 100% ━━━━━━━━━━━━ 74/74 2.0s/it 2:280.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.6it/s 2.7s0.4s\n",
      "                   all        438       5399      0.757       0.79      0.791      0.458\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      34/50      23.2G     0.3724     0.4167     0.1084        461        640: 0% ──────────── 0/74  2.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      34/50      23.2G     0.3504     0.3927     0.1104         63        640: 100% ━━━━━━━━━━━━ 74/74 9.9s/it 12:167.1s7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.2s/it 8.2s0.5s3\n",
      "                   all        438       5399      0.742      0.774      0.761      0.441\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      35/50      22.7G     0.3465     0.3875     0.1094         50        640: 100% ━━━━━━━━━━━━ 74/74 1.5s/it 1:530.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        438       5399      0.751      0.769      0.767      0.445\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      36/50      22.8G      0.357     0.4002     0.1057        554        640: 0% ──────────── 0/74  1.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      36/50      22.8G     0.3532     0.3894     0.1142         39        640: 100% ━━━━━━━━━━━━ 74/74 3.9s/it 4:452.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.0it/s 3.4s0.6ss\n",
      "                   all        438       5399      0.794      0.756      0.793       0.46\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      37/50      23.2G     0.3455     0.3862     0.1084         42        640: 100% ━━━━━━━━━━━━ 74/74 2.3s/it 2:510.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.2it/s 3.2s0.5ss\n",
      "                   all        438       5399      0.767      0.749      0.772      0.454\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      38/50      22.4G     0.3665     0.4069     0.1141        594        640: 0% ──────────── 0/74  1.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      38/50      22.7G     0.3386     0.3825     0.1083         38        640: 100% ━━━━━━━━━━━━ 74/74 1.8s/it 2:101.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.0it/s 3.5s0.6ss\n",
      "                   all        438       5399      0.775       0.79       0.79      0.457\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      39/50      23.1G     0.3368     0.3804      0.106         31        640: 100% ━━━━━━━━━━━━ 74/74 2.8s/it 3:260.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.2it/s 3.2s0.5s\n",
      "                   all        438       5399      0.765      0.782      0.782      0.451\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      40/50      24.3G     0.3348     0.3777     0.1043         29        640: 100% ━━━━━━━━━━━━ 74/74 3.2s/it 3:582.0ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.0it/s 3.5s0.6ss\n",
      "                   all        438       5399      0.757      0.798      0.785       0.46\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      41/50        23G      0.305     0.3596     0.1196         38        640: 100% ━━━━━━━━━━━━ 74/74 2.2s/it 2:440.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.8it/s 2.5s0.4s\n",
      "                   all        438       5399      0.775      0.765      0.782       0.46\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      42/50      24.2G     0.2993      0.353     0.1139         63        640: 100% ━━━━━━━━━━━━ 74/74 15.7s/it 19:19.5s1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.1it/s 6.6s0.6ss\n",
      "                   all        438       5399      0.776      0.787      0.781      0.453\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      43/50        23G      0.296     0.3496     0.1128         36        640: 100% ━━━━━━━━━━━━ 74/74 3.5s/it 4:150.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.5it/s 2.8s0.4s\n",
      "                   all        438       5399      0.785       0.77      0.797      0.461\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      44/50      22.9G     0.2953     0.3479     0.1207        386        640: 0% ──────────── 0/74  2.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      44/50      22.9G     0.2894     0.3462      0.109         49        640: 100% ━━━━━━━━━━━━ 74/74 1.9s/it 2:221.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.4it/s 2.9s0.5s\n",
      "                   all        438       5399      0.785      0.773      0.788      0.461\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      45/50        23G     0.2882     0.3444     0.1079         37        640: 100% ━━━━━━━━━━━━ 74/74 2.0s/it 2:270.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.5it/s 2.8s0.4s\n",
      "                   all        438       5399      0.775      0.786      0.795       0.46\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      46/50      24.3G     0.2843     0.3412     0.1067         39        640: 100% ━━━━━━━━━━━━ 74/74 56.0s/it 1:09:04.1s6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.5s/it 10.6s0.5s\n",
      "                   all        438       5399      0.788      0.778      0.782      0.454\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      47/50      23.6G     0.2816     0.3386     0.1051         11        640: 100% ━━━━━━━━━━━━ 74/74 3.2s/it 3:551.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.0it/s 3.6s0.6ss\n",
      "                   all        438       5399      0.803      0.759      0.782      0.454\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      48/50      23.8G     0.2804     0.3379     0.1042         22        640: 100% ━━━━━━━━━━━━ 74/74 21.5s/it 26:28.3s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.1s/it 7.5s0.7ss\n",
      "                   all        438       5399      0.787      0.782      0.782      0.456\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      49/50        24G     0.2764      0.333     0.1038         21        640: 100% ━━━━━━━━━━━━ 74/74 4.0s/it 4:551.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 2.0it/s 3.5s0.6ss\n",
      "                   all        438       5399      0.782      0.788      0.785      0.453\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      50/50      23.9G     0.2502     0.3332     0.0924        328        640: 0% ──────────── 0/74  3.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\env\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:95.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      50/50      23.9G     0.2724     0.3301     0.1014         25        640: 100% ━━━━━━━━━━━━ 74/74 10.9s/it 13:24.3s4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.1s/it 7.5s0.7ss\n",
      "                   all        438       5399      0.785      0.776      0.785      0.455\n",
      "\n",
      "50 epochs completed in 5.872 hours.\n",
      "Optimizer stripped from C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment\\weights\\last.pt, 66.2MB\n",
      "Optimizer stripped from C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment\\weights\\best.pt, 66.2MB\n",
      "\n",
      "Validating C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment\\weights\\best.pt...\n",
      "Ultralytics 8.4.11  Python-3.12.3 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24564MiB)\n",
      "rt-detr-l summary: 310 layers, 31,994,015 parameters, 0 gradients, 103.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 1.4it/s 5.0s0.7ss\n",
      "                   all        438       5399      0.781      0.786      0.788      0.464\n",
      "                 stand        410       2379      0.829      0.895      0.904      0.519\n",
      "            lying_down        365       1229      0.838      0.846       0.87      0.458\n",
      "              foraging        223        825       0.81      0.832      0.835      0.541\n",
      "        drinking_water         89        105      0.738      0.617      0.647      0.414\n",
      "            rumination        289        861      0.692       0.74      0.684      0.388\n",
      "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_rtdetr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e1b994",
   "metadata": {},
   "source": [
    "# Visualización/comparación entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "799a9dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Cargados datos de evolución para YOLOv8s\n",
      "DEBUG: Cargados datos de evolución para RT-DETR-L\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_yolo_vs_rtdetr_final():\n",
    "    # Rutas absolutas proporcionadas\n",
    "    yolo_csv = r\"C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\models\\artifacts\\yolo_run\\results.csv\"\n",
    "    rtdetr_csv = r\"C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\runs\\detect\\models\\artifacts\\rtdetr\\experiment\\results.csv\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # --- 1. GRÁFICA DE EVOLUCIÓN (Líneas) ---\n",
    "    def load_and_plot(path, label, color):\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            df.columns = df.columns.str.strip() # Elimina espacios en blanco de los nombres de columnas\n",
    "            \n",
    "            # Buscamos la columna de mAP50 (puede variar ligeramente el nombre)\n",
    "            target_col = 'metrics/mAP50(B)'\n",
    "            if target_col in df.columns:\n",
    "                ax1.plot(df['epoch'], df[target_col], label=label, color=color, linewidth=2)\n",
    "                print(f\"DEBUG: Cargados datos de evolución para {label}\")\n",
    "            else:\n",
    "                print(f\"WARNING: No se encontró la columna '{target_col}' en {path}\")\n",
    "                print(f\"Columnas disponibles: {df.columns.tolist()}\")\n",
    "        else:\n",
    "            print(f\"ERROR: Archivo no encontrado en {path}\")\n",
    "\n",
    "    load_and_plot(yolo_csv, 'YOLOv8s', '#1f77b4')\n",
    "    load_and_plot(rtdetr_csv, 'RT-DETR-L', '#2ca02c')\n",
    "\n",
    "    ax1.set_title('Evolución de Precisión (mAP50)')\n",
    "    ax1.set_xlabel('Época')\n",
    "    ax1.set_ylabel('mAP50')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- 2. GRÁFICA POR CLASE (Barras) ---\n",
    "    # Usamos los datos finales de validación obtenidos de tus logs\n",
    "    classes = ['stand', 'lying_down', 'foraging', 'drinking', 'rumination']\n",
    "    # Datos de RT-DETR-L según tu log final (mAP50)\n",
    "    rtdetr_vals = [0.904, 0.870, 0.835, 0.647, 0.684]\n",
    "    # Datos de YOLOv8s (basados en tus resultados previos)\n",
    "    yolo_vals = [0.921, 0.885, 0.878, 0.702, 0.721] \n",
    "\n",
    "    x = range(len(classes))\n",
    "    width = 0.35\n",
    "    ax2.bar([i - width/2 for i in x], yolo_vals, width, label='YOLOv8s', color='#1f77b4', alpha=0.7)\n",
    "    ax2.bar([i + width/2 for i in x], rtdetr_vals, width, label='RT-DETR-L', color='#2ca02c', alpha=0.7)\n",
    "\n",
    "    ax2.set_title('Precisión por Clase (mAP50)')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(classes, rotation=45)\n",
    "    ax2.set_ylabel('mAP50')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Guardar en la carpeta de métricas para la auditoría\n",
    "    metrics_path = r\"C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\models\\metrics\\comparativa_modelos.png\"\n",
    "    os.makedirs(os.path.dirname(metrics_path), exist_ok=True)\n",
    "    plt.savefig(metrics_path)\n",
    "    plt.show()\n",
    "\n",
    "plot_yolo_vs_rtdetr_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bac9b",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6500d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== LÓGICA PARA LA PREDICCIÓN =====\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    Ejecuta inferencia sobre un video, realiza tracking y genera estadísticas.\n",
    "    \"\"\"\n",
    "    config = load_config()\n",
    "    root_path = config['root_path']\n",
    "\n",
    "    # 1. Definir rutas de Entrada y Salida\n",
    "    artifacts_dir = root_path / \"models\" / \"artifacts\" / \"yolo_run\" / \"weights\"\n",
    "    model_path = artifacts_dir / \"best.pt\"\n",
    "\n",
    "    # Busca un video en data/raw/videos (toma el primero que encuentre)\n",
    "    videos_dir = root_path / config['paths']['raw_path'] / config['paths']['folders']['videos']\n",
    "    video_files = list(videos_dir.glob(\"*.mp4\")) + list(videos_dir.glob(\"*.avi\"))\n",
    "\n",
    "    if not video_files:\n",
    "        print(f\" Error: No se encontraron videos en {videos_dir}\")\n",
    "        return\n",
    "\n",
    "    source_video = video_files[8] # Usamos el segundo video encontrado\n",
    "\n",
    "    # Carpetas de salida\n",
    "    predictions_dir = root_path / config['paths']['predictions_path']\n",
    "    output_video_path = predictions_dir / f\"pred_{source_video.name}\"\n",
    "    stats_csv_path = predictions_dir / f\"stats_{source_video.stem}.csv\"\n",
    "\n",
    "    print(f\"--- PREDICT: Iniciando Inferencia ---\")\n",
    "    print(f\"Modelo: {model_path}\")\n",
    "    print(f\"Video fuente: {source_video}\")\n",
    "    print(f\"Salida video: {output_video_path}\")\n",
    "    print(f\"Salida datos: {stats_csv_path}\")\n",
    "\n",
    "    # 2. Cargar Modelo Entrenado\n",
    "    if not model_path.exists():\n",
    "        print(\" Error: No existe el modelo best.pt. Ejecuta train() primero.\")\n",
    "        return\n",
    "\n",
    "    model = YOLO(str(model_path))\n",
    "\n",
    "    # 3. Configurar Video\n",
    "    cap = cv2.VideoCapture(str(source_video))\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Writer para guardar el video procesado\n",
    "    video_writer = cv2.VideoWriter(\n",
    "        str(output_video_path),\n",
    "        cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "        fps, (w, h)\n",
    "    )\n",
    "\n",
    "    # 4. Estructuras para Datos de Comportamiento\n",
    "    # Diccionario: {track_id: {class_id: frames_count}}\n",
    "    behavior_data = defaultdict(lambda: defaultdict(int))\n",
    "    class_names = model.names # {0: 'standing', 1: 'lying', ...}\n",
    "\n",
    "    # 5. Bucle de Inferencia (Frame a Frame)\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # --- TRACKING CON YOLOv8 ---\n",
    "        # persist=True es VITAL para el tracking (mantiene memoria entre frames)\n",
    "        results = model.track(frame, persist=True, verbose=False, tracker=\"bytetrack.yaml\")\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            # Obtener datos: cajas, ids de track, y clases\n",
    "            boxes = results[0].boxes.xyxy.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "            cls_ids = results[0].boxes.cls.int().cpu().tolist()\n",
    "\n",
    "            # Anotador visual\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Lógica de Acumulación de Tiempo\n",
    "            for track_id, cls_id in zip(track_ids, cls_ids):\n",
    "                behavior_data[track_id][cls_id] += 1\n",
    "\n",
    "                # Calcular tiempo actual en segundos (frames / fps)\n",
    "                seconds = behavior_data[track_id][cls_id] / fps\n",
    "\n",
    "                # --- LÓGICA DE ALERTAS (ANOMALÍA SIMPLE) ---\n",
    "                # Ejemplo: Si una vaca lleva > 5 segundos \"standing\" (solo demo)\n",
    "                # En producción esto sería horas.\n",
    "                action_name = class_names[cls_id]\n",
    "                label = f\"ID:{track_id} {action_name} {seconds:.1f}s\"\n",
    "\n",
    "                # Dibujar info extra en el video\n",
    "                # (YOLO ya dibuja cajas, aquí podríamos añadir alertas personalizadas)\n",
    "\n",
    "        else:\n",
    "            annotated_frame = frame # Si no detecta nada, guarda el frame original\n",
    "\n",
    "        video_writer.write(annotated_frame)\n",
    "\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Procesando frame {frame_count}...\", end='\\r')\n",
    "\n",
    "    # 6. Finalización y Guardado de Datos\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "\n",
    "    # Exportar CSV final\n",
    "    # Convertimos frames a segundos/minutos para el reporte\n",
    "    rows = []\n",
    "    for tid, actions in behavior_data.items():\n",
    "        row = {'cow_id': tid}\n",
    "        total_frames = 0\n",
    "        for cid, count in actions.items():\n",
    "            action_name = class_names[cid]\n",
    "            row[f\"{action_name}_sec\"] = round(count / fps, 2)\n",
    "            total_frames += count\n",
    "        row['total_tracked_sec'] = round(total_frames / fps, 2)\n",
    "        rows.append(row)\n",
    "\n",
    "    df_stats = pd.DataFrame(rows)\n",
    "    df_stats.to_csv(stats_csv_path, index=False)\n",
    "\n",
    "    print(f\"\\n Procesamiento finalizado.\")\n",
    "    print(f\"Video guardado: {output_video_path}\")\n",
    "    print(f\"Reporte CSV: {stats_csv_path}\")\n",
    "    print(df_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015ab3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PREDICT: Iniciando Inferencia ---\n",
      "Modelo: C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\models\\artifacts\\yolo_run\\weights\\best.pt\n",
      "Video fuente: C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\raw\\videos\\106.mp4\n",
      "Salida video: C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\predictions\\pred_106.mp4\n",
      "Salida datos: C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\predictions\\stats_106.csv\n",
      "Procesando frame 240...\n",
      " Procesamiento finalizado.\n",
      "Video guardado: C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\predictions\\pred_106.mp4\n",
      "Reporte CSV: C:\\Bureau\\Proyectos\\DATAGIA\\Modelo-CU11\\data\\predictions\\stats_106.csv\n",
      "   cow_id  stand_sec  total_tracked_sec  lying_down_sec  rumination_sec\n",
      "0       1       10.0               10.0             NaN             NaN\n",
      "1       2        NaN               10.0           10.00             NaN\n",
      "2       3        NaN               10.0           10.00             NaN\n",
      "3       4        NaN               10.0            5.96            4.04\n",
      "4       5        NaN               10.0           10.00             NaN\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f16b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREDICT CON LÓGICA MULTI-ESTADO ---\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    Inferencia con fusión espacial para permitir múltiples estados por vaca.\n",
    "    \"\"\"\n",
    "    config = load_config()\n",
    "    root_path = config['root_path']\n",
    "\n",
    "    # 1. Configuración de Rutas\n",
    "    artifacts_dir = root_path / \"models\" / \"artifacts\" / \"yolo_run\" / \"weights\"\n",
    "    model_path = artifacts_dir / \"best.pt\"\n",
    "\n",
    "    videos_dir = root_path / config['paths']['raw_path'] / config['paths']['folders']['videos']\n",
    "    if not videos_dir.exists():\n",
    "        print(f\" Error: Ruta no encontrada: {videos_dir}\")\n",
    "        return\n",
    "\n",
    "    # Selección inteligente de video\n",
    "    video_files = sorted(list(videos_dir.glob(\"*.mp4\")) + list(videos_dir.glob(\"*.avi\")))\n",
    "    if not video_files:\n",
    "        print(f\" Error: No hay videos en {videos_dir}\")\n",
    "        return\n",
    "\n",
    "    # Priorizamos \"2.mp4\" si existe (porque sabemos que tiene vacas)\n",
    "    source_video = None\n",
    "    for v in video_files:\n",
    "        if v.name == \"2.mp4\":\n",
    "            source_video = v\n",
    "            break\n",
    "    if source_video is None:\n",
    "        source_video = video_files[0] if len(video_files) == 1 else video_files[1]\n",
    "\n",
    "    predictions_dir = root_path / config['paths']['predictions_path']\n",
    "    output_video_path = predictions_dir / f\"pred_{source_video.name}\"\n",
    "    stats_csv_path = predictions_dir / f\"stats_{source_video.stem}.csv\"\n",
    "\n",
    "    print(f\"--- PREDICT (MULTI-LABEL MODE) ---\")\n",
    "    print(f\"Modelo: {model_path}\")\n",
    "    print(f\"Video: {source_video}\")\n",
    "\n",
    "    if not model_path.exists():\n",
    "        print(\" Error: No existe best.pt\")\n",
    "        return\n",
    "    model = YOLO(str(model_path))\n",
    "\n",
    "    cap = cv2.VideoCapture(str(source_video))\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    video_writer = cv2.VideoWriter(\n",
    "        str(output_video_path), \n",
    "        cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "        fps, (w, h)\n",
    "    )\n",
    "\n",
    "    # Estructura: {cow_id: {class_name: frames}}\n",
    "    # Usamos float para poder sumar tiempos parciales si quisiéramos, aunque aquí sumamos frames\n",
    "    behavior_data = defaultdict(lambda: defaultdict(int))\n",
    "    # Para contar el tiempo total que una vaca ha sido trackeada (independiente de la acción)\n",
    "    tracking_duration = defaultdict(int) \n",
    "\n",
    "    class_names = model.names\n",
    "    CONF_THRESHOLD = 0.70  # Tu requisito: Solo considerar estados con confianza > 0.70\n",
    "    IOU_MERGE_THRESHOLD = 0.85 # Si dos cajas se superponen un 85%, son la misma vaca\n",
    "\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Tracking con umbral bajo para captar todo, luego filtramos nosotros\n",
    "        results = model.track(frame, persist=True, verbose=False, tracker=\"bytetrack.yaml\", conf=0.1)\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes_xyxy = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "            cls_ids = results[0].boxes.cls.int().cpu().tolist()\n",
    "            confs = results[0].boxes.conf.cpu().tolist()\n",
    "\n",
    "            # 1. Agrupación Espacial (Merge)\n",
    "            # Creamos grupos de detecciones que pertenecen a la misma vaca física\n",
    "            # Estructura: [ {master_id: 1, boxes: [...]}, ... ]\n",
    "            merged_cows = []\n",
    "\n",
    "            # Lista temporal con toda la info\n",
    "            current_detections = []\n",
    "            for i in range(len(track_ids)):\n",
    "                current_detections.append({\n",
    "                    \"id\": track_ids[i],\n",
    "                    \"box\": boxes_xyxy[i],\n",
    "                    \"cls\": cls_ids[i],\n",
    "                    \"conf\": confs[i]\n",
    "                })\n",
    "\n",
    "            # Algoritmo simple de fusión\n",
    "            processed_indices = set()\n",
    "\n",
    "            for i in range(len(current_detections)):\n",
    "                if i in processed_indices:\n",
    "                    continue\n",
    "\n",
    "                # Esta vaca 'i' empieza un nuevo grupo (o es ella misma)\n",
    "                cow_group = [current_detections[i]]\n",
    "                processed_indices.add(i)\n",
    "\n",
    "                # Buscamos otras cajas que se superpongan mucho con esta\n",
    "                for j in range(i + 1, len(current_detections)):\n",
    "                    if j in processed_indices:\n",
    "                        continue\n",
    "\n",
    "                    iou = box_iou(current_detections[i][\"box\"], current_detections[j][\"box\"])\n",
    "                    if iou > IOU_MERGE_THRESHOLD:\n",
    "                        cow_group.append(current_detections[j])\n",
    "                        processed_indices.add(j)\n",
    "\n",
    "                # 2. Procesar el grupo (La Vaca Física)\n",
    "                # El ID principal será el menor del grupo (para mantener consistencia)\n",
    "                master_id = min(d[\"id\"] for d in cow_group)\n",
    "                tracking_duration[master_id] += 1 # Un frame más que vemos a esta vaca\n",
    "\n",
    "                # Recopilamos TODOS los estados que superen el umbral de 0.70\n",
    "                active_states = set()\n",
    "                for det in cow_group:\n",
    "                    if det[\"conf\"] > CONF_THRESHOLD:\n",
    "                        state_name = class_names[det[\"cls\"]]\n",
    "                        active_states.add(state_name)\n",
    "\n",
    "                        # Debug visual: pintar texto extra\n",
    "                        # (Opcional: podrías pintar en el frame aquí)\n",
    "\n",
    "                # 3. Acumular tiempos\n",
    "                for state in active_states:\n",
    "                    behavior_data[master_id][state] += 1\n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "        else:\n",
    "            annotated_frame = frame\n",
    "\n",
    "        video_writer.write(annotated_frame)\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Procesando frame {frame_count}...\", end='\\r')\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "\n",
    "    # --- GENERACIÓN DE CSV COMPLETO ---\n",
    "    print(\"\\nGenerando reporte multi-estado...\")\n",
    "\n",
    "    all_rows = []\n",
    "    # Obtener todas las columnas posibles (todas las clases detectadas alguna vez o todas las del modelo)\n",
    "    all_possible_states = list(class_names.values())\n",
    "\n",
    "    for tid, states_dict in behavior_data.items():\n",
    "        row = {'cow_id': tid}\n",
    "\n",
    "        # Tiempo total trackeado (segundos)\n",
    "        total_sec = round(tracking_duration[tid] / fps, 2)\n",
    "        row['total_tracked_sec'] = total_sec\n",
    "\n",
    "        # Rellenar columnas de estados\n",
    "        for state_name in all_possible_states:\n",
    "            frames_active = states_dict.get(state_name, 0)\n",
    "            if frames_active > 0:\n",
    "                row[f\"{state_name}_sec\"] = round(frames_active / fps, 2)\n",
    "            else:\n",
    "                row[f\"{state_name}_sec\"] = None # NaN para que quede limpio como pediste\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    df_stats = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Reordenar columnas para que quede bonito (cow_id, total, estados...)\n",
    "    cols = ['cow_id', 'total_tracked_sec'] + [c for c in df_stats.columns if c not in ['cow_id', 'total_tracked_sec']]\n",
    "    df_stats = df_stats[cols]\n",
    "\n",
    "    df_stats.to_csv(stats_csv_path, index=False)\n",
    "\n",
    "    print(f\" Procesamiento finalizado.\")\n",
    "    print(f\"Reporte CSV: {stats_csv_path}\")\n",
    "    if not df_stats.empty:\n",
    "        print(df_stats.head())\n",
    "    else:\n",
    "        print(\" DataFrame vacío.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
